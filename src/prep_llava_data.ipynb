{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['COCO_DIR'] = '/usr1/data/mingqia2/datasets/coco/'\n",
    "os.environ['AOKVQA_DIR'] = '/usr1/data/mingqia2/aokvqa/'\n",
    "os.environ['HF_HOME'] = '/usr1/data/models_cache'\n",
    "\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coco_path(split, image_id, coco_dir):\n",
    "    return os.path.join(coco_dir, f\"{split}2017\", f\"{image_id:012}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_llava_format(input_path, output_path, coco_dir, split='train'):\n",
    "    # Load the original dataset\n",
    "    with open(input_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    converted = []\n",
    "    for entry in data:\n",
    "        question_id = entry.get(\"question_id\")\n",
    "        image_id = entry.get(\"image_id\")\n",
    "        question = entry.get(\"question\", \"\")\n",
    "        rationales = \" \".join(entry.get(\"rationales\", []))\n",
    "        viper_gpt = entry.get(\"viper_gpt\", {})\n",
    "        viper_response = viper_gpt.get(\"viper_response\", \"\")\n",
    "        # choices = entry.get(\"choices\", [])\n",
    "        \n",
    "        image_path = get_coco_path(split, image_id, coco_dir)\n",
    "        # Find the most frequent direct answer\n",
    "        direct_answers = entry.get(\"direct_answers\", [])\n",
    "        if direct_answers:\n",
    "            freq = Counter(direct_answers)\n",
    "            most_common_answer, _ = freq.most_common(1)[0]\n",
    "        else:\n",
    "            most_common_answer = \"\"\n",
    "\n",
    "        da_prompt = (\n",
    "            f\"<image>\\nQuestion: {question}\\n\"\n",
    "            + f\"\\nVisual Clues: {viper_response}\\n\"   \n",
    "            \"Please provide a rationale and then return the letter of the correct answer in the format: \"\n",
    "            \"'Rationale: [your explanation] \\\\n Answer: [your answer]'.\" \n",
    "        )\n",
    "        da_answer = f\"Rationales: {rationales} \\\\n Answer: {most_common_answer}\"\n",
    "            \n",
    "        formatted_choices = ', '.join([f\"{chr(65 + i)}: {choice}\" for i, choice in enumerate(entry['choices'])])\n",
    "        correct_choice = chr(65 + entry[\"correct_choice_idx\"]) # Convert index to letter\n",
    "       \n",
    "        mc_prompt = (\n",
    "            f\"Question: {question} \\n Visual Clues: {viper_response} \\n Choices: {formatted_choices}. \"\n",
    "            \"Please provide a rationale and then return the letter of the correct answer in the format: \"\n",
    "            \"'Rationale: [your explanation] \\\\n Answer: [your answer]'.\"\n",
    "        )\n",
    "        mc_answer = f\"Rationales: {rationales} \\\\n Answer: {correct_choice}\"\n",
    "        \n",
    "        da_query = {\n",
    "            \"id\": question_id,\n",
    "            \"image\": image_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": da_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": da_answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        mc_query = {\n",
    "            \"id\": question_id,\n",
    "            \"image\": image_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": mc_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": mc_answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        converted.append(da_query)\n",
    "        converted.append(mc_query)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(converted, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dir = os.getenv('COCO_DIR')\n",
    "aokvqa_dir = os.getenv('AOKVQA_DIR')\n",
    "\n",
    "original_train = \"../results/viper_augmentations/aokvqa_plus_viper_train.json\"\n",
    "converted_train = \"../results/viper_augmentations/llava_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_llava_format(original_train, converted_train, coco_dir, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aokvqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
